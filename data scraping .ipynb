{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***library requirement install if needed***\n",
    "pip install beautifulsoup4\n",
    "pip install lxml\n",
    "pip install html5lib\n",
    "pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**check if the coursera has a API ???? if not **\n",
    "**structure of URL \n",
    "Page 1 : https://www.coursera.org/learn/inferential-statistical-analysis-python/reviews\n",
    "Page 2 : https://www.coursera.org/learn/inferential-statistical-analysis-python/reviews?page=2\n",
    "Page 10 : https://www.coursera.org/learn/inferential-statistical-analysis-python/reviews?page=10\n",
    "Question : When to stop ? if we dont know the last page n = ??\n",
    "store in in CSV for cleaning or then uploaded to SQL then python request for cleaning ???? \n",
    "if it's a dynamic plaform ???\n",
    "request with time if not will dammage the website \n",
    "#extract only rating star in separate column ? \n",
    "#we need to scapping the feed back as much as possible in different subject ( statistic/Python/SQL/...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation of beautifulSoup \n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL   need to make a loop with page ???\n",
    "#for n in range(100)\n",
    "# URL = f'https://www.coursera.org/learn/inferential-statistical-analysis-python/reviews?page=n\n",
    "URL = 'https://www.coursera.org/learn/inferential-statistical-analysis-python/reviews'  \n",
    "page = requests.get(URL)                                                               # requests URL\n",
    "soup = BeautifulSoup(page.content, 'html.parser')                                      # Html parsing \n",
    "\n",
    "print(soup.prettify())                                                      # print the resquest page with function Prettify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print title of the page \n",
    "\n",
    "title=soup.title  #print title \n",
    "print(title.text) #get only text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print example 1 reveiwText / in python class is a function , then in Beautifulsoup will be class_\n",
    "reviewText=soup.find('div',class_='reviewText')\n",
    "print(reviewText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean somes codes to take only text.  p  stands for paragraph. \n",
    "match=reviewText.p.text\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all the reviewtext and cleaning the other code    #How to separate the text and save it in \n",
    "for  reviewText in soup.find_all('div',class_='reviewText'):\n",
    "    match=reviewText.p                 ##add .text will have only \n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save in CSV\n",
    "#CSV_File=open('coursera_scraping.csv','w')\n",
    "#csv_writer= csv.writer(CSV_File)\n",
    "#csv_writer.writerow(['name', 'review', 'rating'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
